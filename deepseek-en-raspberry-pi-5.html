<!DOCTYPE html SYSTEM "about:legacy-compat">
<html lang="en-US" data-preset="contrast" data-primary-color="#B42F42"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="robots" content="noindex"><meta name="built-on" content="2025-01-31T23:27:30.1951321"><title>Deepseek en Raspberry PI 5 | Dangos.dev</title><script type="application/json" id="virtual-toc-data">[{"id":"-vvfb74_5","level":0,"title":"Requisitos previos","anchor":"#-vvfb74_5"},{"id":"-vvfb74_6","level":0,"title":"Paso 1: Preparación inicial","anchor":"#-vvfb74_6"},{"id":"-vvfb74_7","level":0,"title":"Paso 2: Instalar Ollama","anchor":"#-vvfb74_7"},{"id":"-vvfb74_8","level":0,"title":"Paso 3: Despliegue de DeepSeek-R1","anchor":"#-vvfb74_8"},{"id":"-vvfb74_9","level":0,"title":"Análisis de resultados","anchor":"#-vvfb74_9"}]</script><script type="application/json" id="topic-shortcuts"></script><link href="https://resources.jetbrains.com/writerside/apidoc/6.10.0-b575/app.css" rel="stylesheet"><link rel="icon" type="image/png" sizes="16x16" href="images/logo-dango.png"><meta name="image" content=""><!-- Open Graph --><meta property="og:title" content="Deepseek en Raspberry PI 5 | Dangos.dev"><meta property="og:description" content=""><meta property="og:image" content=""><meta property="og:site_name" content="Dangos.dev Help"><meta property="og:type" content="website"><meta property="og:locale" content="en_US"><meta property="og:url" content="writerside-documentation/deepseek-en-raspberry-pi-5.html"><!-- End Open Graph --><!-- Twitter Card --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content=""><meta name="twitter:title" content="Deepseek en Raspberry PI 5 | Dangos.dev"><meta name="twitter:description" content=""><meta name="twitter:creator" content=""><meta name="twitter:image:src" content=""><!-- End Twitter Card --><!-- Schema.org WebPage --><script type="application/ld+json">{
    "@context": "http://schema.org",
    "@type": "WebPage",
    "@id": "writerside-documentation/deepseek-en-raspberry-pi-5.html#webpage",
    "url": "writerside-documentation/deepseek-en-raspberry-pi-5.html",
    "name": "Deepseek en Raspberry PI 5 | Dangos.dev",
    "description": "",
    "image": "",
    "inLanguage":"en-US"
}</script><!-- End Schema.org --><!-- Schema.org WebSite --><script type="application/ld+json">{
    "@type": "WebSite",
    "@id": "writerside-documentation/#website",
    "url": "writerside-documentation/",
    "name": "Dangos.dev Help"
}</script><!-- End Schema.org --></head><body data-id="Deepseek-en-Raspberry-PI-5" data-main-title="Deepseek en Raspberry PI 5" data-article-props="{&quot;seeAlsoStyle&quot;:&quot;links&quot;}" data-template="article" data-breadcrumbs=""><div class="wrapper"><main class="panel _main"><header class="panel__header"><div class="container"><h3>Dangos.dev  Help</h3><div class="panel-trigger"></div></div></header><section class="panel__content"><div class="container"><article class="article" data-shortcut-switcher="inactive"><h1 data-toc="Deepseek-en-Raspberry-PI-5" id="Deepseek-en-Raspberry-PI-5.topic">Deepseek en Raspberry PI 5</h1><p id="-vvfb74_2">Hace unos d&iacute;as, un compa&ntilde;ero de trabajo comenz&oacute; a inundar mi bandeja de entrada con art&iacute;culos t&eacute;cnicos, benchmarks y repositorios de DeepSeek, un modelo de lenguaje orientado a razonamiento matem&aacute;tico y coding.</p><p id="-vvfb74_3">Al principio no present&eacute; inter&eacute;s en el nuevo modelo (todo el tiempo sale una nueva IA revolucionaria), pero tras ver su persistencia (y un benchmark donde DeepSeek superaba a Llama2-7B en tareas de optimizaci&oacute;n de c&oacute;digo), decid&iacute; explorarla poni&eacute;ndome como reto ejecutarlo en una Raspberry Pi.</p><p id="-vvfb74_4">Este art&iacute;culo no es solo una gu&iacute;a t&eacute;cnica. Es la demostraci&oacute;n de que que los LLMs edge ya no son exclusivos de GPUs costosas.</p><section class="chapter"><h2 id="-vvfb74_5" data-toc="-vvfb74_5">Requisitos previos</h2><section class="procedure-steps" id="-vvfb74_10"><ul class="list _bullet" id="-vvfb74_11"><li class="list__item" id="-vvfb74_12"><p><b id="-vvfb74_14">Raspberry Pi 5 Modelo B (8 GB RAM)</b>: Configurada con Raspberry Pi OS 64-bit para aprovechar el espacio de direcciones ARMv8.</p></li><li class="list__item" id="-vvfb74_13"><p><b id="-vvfb74_15">Ollama v0.1.27+</b>: Herramienta cr&iacute;tica para gestionar modelos GGUF, aunque presentar errores en ARM.</p></li></ul><ol class="list _decimal"></ol></section></section><section class="chapter"><h2 id="-vvfb74_6" data-toc="-vvfb74_6">Paso 1: Preparaci&oacute;n inicial</h2><section class="procedure-steps" id="-vvfb74_16"><ol class="list _decimal"><li class="list__item" id="-vvfb74_17"><p><b id="-vvfb74_20">Acceso remoto</b>: Configur&eacute; SSH con claves RSA para seguridad, usando JetBrains Gateway por integraci&oacute;n con el IDE.</p></li><li class="list__item" id="-vvfb74_18"><p><b id="-vvfb74_21">Actualizaci&oacute;n de paquetes</b>: Esencial para evitar conflictos con bibliotecas compartidas: </p><div class="code-block" data-lang="bash">
                    sudo apt update
                    sudo apt upgrade -y
                </div></li><li class="list__item" id="-vvfb74_19"><p>El paquete curl suele venir preinstalado en Raspberry Pi OS, pero es recomendable verificarlo. </p><div class="code-block" data-lang="bash">
                    sudo apt install curl -y
                </div></li></ol></section></section><section class="chapter"><h2 id="-vvfb74_7" data-toc="-vvfb74_7">Paso 2: Instalar Ollama</h2><section class="procedure-steps" id="-vvfb74_24"><p>Ollama es un marco ligero para ejecutar LLMs localmente. Aunque no es oficialmente compatible con ARM, funciona en Raspberry Pi 5 usando la versi&oacute;n Linux ARM64: </p><ol class="list _decimal"><li class="list__item" id="-vvfb74_25"><p>Descargar e instalar Ollama: </p><div class="code-block" data-lang="bash">
                    curl -fsSL https://ollama.com/install.sh | sh
                </div></li><li class="list__item" id="-vvfb74_26"><p>Verificar la instalaci&oacute;n: </p><div class="code-block" data-lang="bash">
                    ollama --version
                    # Debe mostrar: &quot;ollama version 0.1.x&quot;
                </div></li></ol></section></section><section class="chapter"><h2 id="-vvfb74_8" data-toc="-vvfb74_8">Paso 3: Despliegue de DeepSeek-R1</h2><section class="procedure-steps" id="-vvfb74_29"><ol class="list _decimal"><li class="list__item" id="-vvfb74_30"><p><b id="-vvfb74_32">Descarga y ejecuci&oacute;n</b>: </p><div class="code-block" data-lang="bash">
                ollama run deepseek-r1:1.5b
            </div></li><li class="list__item" id="-vvfb74_31"><p><b id="-vvfb74_34">Prueba de concepto</b>: </p><figure id="-vvfb74_35"><img alt="Respondiendo a la pregunta '&iquest;Qu&eacute; es una derivada?'" src="images/deepseek_demo1.png" title="Respondiendo a la pregunta '&iquest;Qu&eacute; es una derivada?'" width="731" height="831"></figure></li></ol></section></section><section class="chapter"><h2 id="-vvfb74_9" data-toc="-vvfb74_9">An&aacute;lisis de resultados</h2><div class="table-wrapper"><table class="wide" id="-vvfb74_36"><thead><tr class="ijRowHead" id="-vvfb74_40"><th id="-vvfb74_43"><p>M&eacute;trica</p></th><th id="-vvfb74_44"><p>Valor</p></th><th id="-vvfb74_45"><p>Implicaci&oacute;n t&eacute;cnica</p></th></tr></thead><tbody><tr id="-vvfb74_41"><td id="-vvfb74_46"><p>Uso de RAM</p></td><td id="-vvfb74_47"><p>3.8 GB</p></td><td id="-vvfb74_48"><p>Requiere gesti&oacute;n activa de swap en Pi de 4 GB</p></td></tr><tr id="-vvfb74_42"><td id="-vvfb74_49"><p>Temperatura CPU</p></td><td id="-vvfb74_50"><p>72&deg;C (sin cooling activo)</p></td><td id="-vvfb74_51"><p>Necesidad de disipador pasivo</p></td></tr></tbody></table></div><p id="-vvfb74_37">Debido a la gran cantidad de recursos que puede consumir ejecutar un modelo de inteligencia artificial localmente, es recomendable tener suficiente memoria y procesamiento.</p><p id="-vvfb74_38">Disponer de una GPU, aumentar el swap, usar modelos destilados y monitorear la ventilaci&oacute;n son actividades que ayudar&aacute;n a la ejecuci&oacute;n flu&iacute;da del modelo.</p><div class="code-block" data-lang="bash">
                # Aumentar el swap modificando CONF_SWAPSIZE=4096, por ejemplo
                sudo nano /etc/dphys-swapfile
                sudo systemctl restart dphys-swapfile
            </div></section><p> &iquest;Vali&oacute; la pena el intento? Absolutamente. Como prueba de concepto, demuestra que los LLMs accesibles ya est&aacute;n aqu&iacute;.</p><div class="last-modified">Last modified: 01 February 2025</div><div data-feedback-placeholder="true"></div><div class="navigation-links _bottom"><a href="dangos-dev.html" class="navigation-links__prev">Dangos.dev</a></div></article><div id="disqus_thread"></div></div></section></main></div><script src="https://resources.jetbrains.com/writerside/apidoc/6.10.0-b575/app.js"></script></body></html>